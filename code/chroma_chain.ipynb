{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from getpass import getpass\n",
    "from langchain_openai import OpenAI\n",
    "import os\n",
    "\n",
    "from uuid import uuid4\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workbench/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_folder_dir = '../../data'\n",
    "HUGGINGFACEHUB_API_TOKEN = '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'\n",
    "\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = HUGGINGFACEHUB_API_TOKEN\n",
    "\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': False, 'clean_up_tokenization_spaces': True}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "# data folder is in the parent folder of the code folder on the level abolve\n",
    "data_folder_dir = '../data'\n",
    "# /home/workbench/nvidia-workbench/HackAI2024-DataWise/data\n",
    "# read the Store 1 - Items List.csv in the data folder\n",
    "store1_items_list = pd.read_csv(os.path.join(data_folder_dir, 'Store 1 - Items List.csv'))\n",
    "# append the store number to the store1_items_list as a column on the left\n",
    "store1_items_list.insert(0, 'Store', 'Latte Labs')\n",
    "# same goes for store 2\n",
    "store2_items_list = pd.read_csv(os.path.join(data_folder_dir, 'Store 2 - Items List.csv'))\n",
    "store2_items_list.insert(0, 'Store', 'Darcy Drinks')\n",
    "# now combine the two dataframes into one\n",
    "store_items_list = pd.concat([store1_items_list, store2_items_list])\n",
    "# store it in the csv file sample_data.csv\n",
    "# store_items_list.to_csv(os.path.join(data_folder_dir, 'sample_data.csv'), index=False)\n",
    "# iterate through store_items_list and print the item name and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_document(document_metadata):\n",
    "    API_KEY = 'secret_testingreport-grafana_88c10e40213144f58eb24acb9fa1a1c3.IEDFHewBrwVx7ccd2SUshQcMXb3bqccK'\n",
    "\n",
    "    openai_api_key = API_KEY\n",
    "    openai_api_base = \"https://api.lambdalabs.com/v1\"\n",
    "    llm = OpenAI(    \n",
    "            api_key=openai_api_key,\n",
    "            base_url=openai_api_base,\n",
    "            temperature=0.5,\n",
    "            model_name=\"/models/LiquidCloud\",\n",
    "            )\n",
    "    \n",
    "    # Remove all spaces from document_metadata keys\n",
    "    document_metadata = {k.replace(' ', ''): v for k, v in document_metadata.items()}\n",
    "    print(document_metadata)\n",
    "    \n",
    "    # Define the system prompt\n",
    "    system_prompt = \"You are an AI assistant that generates corporate documents for coffee shops.\"\n",
    "\n",
    "    # Combine system prompt with the user prompt\n",
    "    user_prompt = \"Given the following data: \\n\" \\\n",
    "                  \"Store: {Store} \\n\" \\\n",
    "                  \"Business Line: {BusinessLine} \\n\" \\\n",
    "                  \"Item Name: {ItemName} \\n\" \\\n",
    "                  \"Abbreviation for Item Name: {AbbreviationforItemName} \\n\" \\\n",
    "                  \"Generate a hypothetical corporate document for a coffee shop based on the given metadata.\"\n",
    "\n",
    "    # Create the full prompt template\n",
    "    full_prompt = f\"{system_prompt}\\n\\n{user_prompt}\"\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(full_prompt)\n",
    "    chain = prompt | llm\n",
    "    return chain.invoke(document_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_document({'Store': 'Latte Labs', 'Business Line': 'Drink', 'Item Name': 'Coffee', 'Abbreviation for Item Name': 'Coff'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = False\n",
    "if generate:\n",
    "    documents =[\n",
    "    Document(\n",
    "    page_content=gen_document(item[1].to_dict()),\n",
    "    metadata=item[1].to_dict(),\n",
    "    id=item[0],\n",
    "    ) for item in store_items_list.iterrows()]\n",
    "    uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "    vector_store = Chroma(\n",
    "        collection_name=\"example_collection\",\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=\"../chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    "    )\n",
    "    vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"/project/data/chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    # get all documents in /project/data/documents\n",
    "    # get all files under /project/data/documents\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk('/project/data/documents'):\n",
    "        for file in files:\n",
    "            file_list.append(file)\n",
    "\n",
    "    # sort the files based on document id which is the second part of the file name doc_{id}.txt\n",
    "    file_list.sort(key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "    documents =[\n",
    "        Document(\n",
    "        page_content=open(f'/project/data/documents/{file_list[item[0]]}', 'r').read(),\n",
    "        metadata=item[1].to_dict(),\n",
    "        id=item[0],\n",
    "        ) for item in store_items_list.iterrows()]\n",
    "    uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "    vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'Abbreviation for Item Name': 'ChoSha', 'Business Line': 'Drink', 'Item Name': 'Chocolate Shake', 'Store': 'Darcy Drinks'}, page_content='\\n\\nDocument Title: Latte Labs Iced Latte Sales Report\\n\\nDocument Purpose: To provide an analysis of the Iced Latte sales for the month of July.\\n\\nDocument Content:\\n\\nDear Latte Labs Team,\\n\\nI am pleased to present the Iced Latte Sales Report for the month of July. This report is designed to provide a comprehensive analysis of our Iced Latte sales, allowing us to understand our performance and identify areas for improvement.\\n\\nThe Iced Latte, abbreviated as IcedLatt, has been a staple in our Drink business line. It has consistently been a customer favorite due to its refreshing taste and the perfect balance of coffee and cream.\\n\\nOur sales data for July shows a promising trend. The IcedLatt has seen a steady increase in sales, with a 15% rise compared to the same period last year. This growth can be attributed to our successful marketing campaigns and the excellent quality of our product.\\n\\nHowever, there is still room for improvement. We need to ensure that our IcedLatt is available at all times, as we have noticed a slight dip in sales during peak hours due to stock shortages. We are also looking into ways to further enhance'), Document(metadata={'Abbreviation for Item Name': 'HamSan', 'Business Line': 'Food', 'Item Name': 'Ham Sandwich', 'Store': 'Darcy Drinks'}, page_content='\\n\\nThe document is a draft for a new menu item, the Iced Matcha.\\n\\nDraft for New Menu Item: Iced Matcha\\n\\nDate: [Current Date]\\n\\nTo: [Recipient\\'s Name]\\n\\nFrom: [Your Name], [Your Position]\\n\\nSubject: Draft for New Menu Item: Iced Matcha\\n\\nDear [Recipient\\'s Name],\\n\\nI hope this message finds you well. I am writing to present a draft for a new menu item that we are considering to add to our Latte Labs\\' offerings. \\n\\nAfter careful consideration and market research, we believe that the Iced Matcha is a product that could significantly enhance our current beverage lineup, and align with our business line of drinks.\\n\\nThe Iced Matcha is a refreshing, health-conscious beverage that is gaining popularity among consumers who are looking for alternatives to traditional coffee drinks. Made from high-quality, finely ground green tea leaves, this drink is not only delicious but also packed with antioxidants.\\n\\nThe proposed name for this item is \"Iced Matcha\", with the abbreviation \"IcedMatc\". This name choice reflects the product\\'s unique blend of traditional Japanese')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = vector_store.similarity_search(\n",
    "    \"coffee\",\n",
    "    k=2,\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x7faf213acac0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directory ../../data/documents if it does not exist\n",
    "# os.makedirs('../../data/documents', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make directory ../../data/documents if it does not exist\n",
    "# os.makedirs('../../data/documents', exist_ok=True)\n",
    "# # save the documents to a text file\n",
    "# for i, doc in enumerate(documents):\n",
    "#     with open(f'../../data/documents/doc_{i}.txt', 'w') as f:\n",
    "#         f.write(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "loader = CSVLoader('test.csv')\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "embedded_doc = embeddings.embed_documents(text.page_content for text in data)\n",
    "print(embedded_doc)\n",
    "\n",
    "\n",
    "def embed_text():\n",
    "    loader = CSVLoader(os.path.join(data_folder_dir, 'sample_data.csv'))\n",
    "\n",
    "    data = loader.load()\n",
    "\n",
    "    # Fix the generator expression to a list comprehension\n",
    "    embedded_doc = embeddings.embed_documents([text.page_content for text in data])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
